FullyShardedDataParallel
========================

.. automodule:: torch.distributed.fsdp

.. autoclass:: torch.distributed.fsdp.FullyShardedDataParallel
  :members:

.. autoclass:: torch.distributed.fsdp.BackwardPrefetch
  :members:

.. autoclass:: torch.distributed.fsdp.ShardingStrategy
  :members:

.. autoclass:: torch.distributed.fsdp.MixedPrecision
  :members:

.. autoclass:: torch.distributed.fsdp.CPUOffload
  :members:

.. autoclass:: torch.distributed.fsdp.api.StateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.FullStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.ShardedStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.LocalStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.OptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.FullOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.ShardedOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.LocalOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.api.StateDictSettings
  :members:
